{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2714a931",
   "metadata": {},
   "source": [
    "## 1. Fixing Forecasted Values for Independent Features with Poor Performance:\n",
    "This is done to get the validation metrics for each forecasted independent feature. Those features with poor MAPE (>0.4) will be modelled again using Poisson Distribution and Exponential Smoothing - Holt-Winters Method. We will then take the forecasted values of the model with minimum MAPE value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ed196a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from statsmodels.discrete.count_model import Poisson\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70f13ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_data_dict = {}\n",
    "val_data_dict = {}\n",
    "\n",
    "csv_names = ['engine_1',\n",
    " 'engine_2',\n",
    " 'engine_3',\n",
    " 'engine_5',\n",
    " 'engine_7',\n",
    " 'engine_8',\n",
    " 'engine_9',\n",
    " 'engine_10_truck_2',\n",
    " 'engine_12',\n",
    " 'engine_13_truck_10',\n",
    " 'engine_16_truck_6',\n",
    " 'engine_17_rescue_11',\n",
    " 'engine_19',\n",
    " 'truck_3',\n",
    " 'truck_4',\n",
    " 'truck_5']\n",
    "\n",
    "for i in csv_names:\n",
    "    globals()[i+'_fc'] = pd.read_csv(f'/Users/medhinisridharr/Documents/University of Rochester/Courses/Fall 2024/Capstone Project/monthly_incident_counts/Forecasted Selected Features/Past_Future/{i}_past_future.csv')\n",
    "    globals()[i+'_val'] = pd.read_csv(f'/Users/medhinisridharr/Documents/University of Rochester/Courses/Fall 2024/Capstone Project/monthly_incident_counts/Forecasted Selected Features/validation_metrics/{i}_fc_val.csv')\n",
    "    \n",
    "    if 'time_to_reach' in globals()[i+'_fc']:\n",
    "        globals()[i+'_fc'].drop('time_to_reach',axis=1,inplace=True)\n",
    "        \n",
    "    if 'time_to_reach' in globals()[i+'_val']:\n",
    "        globals()[i+'_val'].drop('time_to_reach',axis=1,inplace=True)\n",
    "        \n",
    "    forecasts_data_dict[i+'_fc'] = globals()[i+'_fc']\n",
    "    \n",
    "    if 'Unnamed: 0' in globals()[i+'_val'].columns:\n",
    "        globals()[i+'_val'].rename(columns={'Unnamed: 0':'feature'},inplace=True)\n",
    "        \n",
    "    val_data_dict[i+'_val'] = globals()[i+'_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfd63da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for val_df in list(val_data_dict.keys())[:8]:\n",
    "    cols = list(globals()[val_df].columns)\n",
    "    globals()[val_df]['feature'] = ['RMSE','MAE','MAPE','AIC','BIC']\n",
    "    globals()[val_df] = globals()[val_df][['feature']+cols]\n",
    "    val_data_dict[val_df] = globals()[val_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4413d188",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_transpose_dict = {}\n",
    "for k in val_data_dict.keys():\n",
    "    globals()[k+'_t'] = val_data_dict[k].T.reset_index()\n",
    "    globals()[k+'_t'].columns = globals()[k+'_t'].loc[0]\n",
    "    assert list(globals()[k+'_t'].columns) == ['feature', 'RMSE', 'MAE', 'MAPE', 'AIC', 'BIC']\n",
    "    globals()[k+'_t'] = globals()[k+'_t'].loc[1:].reset_index(drop=True)\n",
    "    val_data_transpose_dict[k] = globals()[k+'_t']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79be0b93",
   "metadata": {},
   "source": [
    "- Created the improve_forecast() to look at poorly forecasted features and run Poisson Distribution and ETS models to get alternate forecasts. The one with least MAPE is chosen and the forecasted values are replaced in the data before predicting monthly counts based on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db77378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def improve_forecast(df, df_val, df_val_t, poor_forecast):\n",
    "    print(poor_forecast)\n",
    "    \n",
    "    df.rename(columns={'datetimealarm_month_year':'ds'},inplace=True)\n",
    "    sarimax_forecasts = df.copy()\n",
    "    \n",
    "    final_forecasts = sarimax_forecasts[['ds']].copy()  # Include the datetime column\n",
    "    \n",
    "    for feature in poor_forecast:\n",
    "        print(f\"Processing feature: {feature}\")\n",
    "\n",
    "        # Extract the data for the feature\n",
    "        feature_data = sarimax_forecasts[['ds', feature]].copy()\n",
    "        feature_data[feature] = feature_data[feature].apply(lambda x: max(0, x))  # Ensure no negative values\n",
    "\n",
    "        # Split data into train (historical) and test (validation) for MAPE calculation\n",
    "        train_data = feature_data[feature_data['ds']<\"2023-01\"][feature]  # Historical data\n",
    "        test_data = feature_data[(feature_data['ds'] >= \"2023-01\") & (feature_data['ds'] <= \"2024-09\")][feature]  # Jan 2023 to Sep 2024\n",
    "\n",
    "        # SARIMAX MAPE (validation on test_data)\n",
    "        sarimax_mape = df_val.loc[df_val['feature']=='MAPE',feature].tolist()[0]\n",
    "        print(f\"SARIMAX MAPE for {feature}: {sarimax_mape}\")\n",
    "\n",
    "        # Initialize alternative model forecast\n",
    "        alternative_forecast_poisson = None\n",
    "        alternative_mape_poisson = None\n",
    "\n",
    "        alternative_forecast_ets = None\n",
    "        alternative_mape_ets = None\n",
    "\n",
    "        # Prepare training data for Poisson\n",
    "        y_train = train_data.values\n",
    "        X_train = np.arange(len(y_train)).reshape(-1, 1)  # Example: Simple index as regressor\n",
    "        \n",
    "        X_test = np.arange(len(y_train), len(y_train) + len(test_data)).reshape(-1, 1)\n",
    "\n",
    "        # Fit Poisson model\n",
    "        poisson_model = Poisson(y_train, X_train).fit(disp=False)\n",
    "        alternative_forecast_poisson = poisson_model.predict(X_test)\n",
    "        alternative_mape_poisson = mean_absolute_percentage_error(test_data, alternative_forecast_poisson)\n",
    "        print(f\"Alternative Model MAPE for {feature}: {alternative_mape_poisson}\")\n",
    "\n",
    "        # Fit ETS model\n",
    "        ets_model = ExponentialSmoothing(\n",
    "            train_data,\n",
    "            seasonal=\"add\",  # Example: Additive seasonality\n",
    "            seasonal_periods=12  # Example: Monthly seasonality\n",
    "        ).fit()\n",
    "\n",
    "        # Calculate MAPE for the alternative model\n",
    "        alternative_forecast_ets = ets_model.forecast(len(test_data))\n",
    "        alternative_mape_ets = mean_absolute_percentage_error(test_data, alternative_forecast_ets)\n",
    "        print(f\"Alternative Model MAPE for {feature}: {alternative_mape_ets}\")\n",
    "\n",
    "        best_mape = min([alternative_mape_poisson,alternative_mape_ets,sarimax_mape])\n",
    "        \n",
    "        y_full_train = feature_data[feature_data['ds'] < \"2024-10\"][feature].values\n",
    "        X_full_train = np.arange(len(y_full_train)).reshape(-1, 1)\n",
    "        X_future = np.arange(len(y_full_train), len(y_full_train) + 120).reshape(-1, 1)\n",
    "\n",
    "        if best_mape == alternative_mape_poisson:\n",
    "            print(f\"Using Poisson model forecast for {feature}\")\n",
    "            poisson_model = Poisson(y_full_train, X_full_train).fit(disp=False)\n",
    "            alternative_forecast_poisson = poisson_model.predict(X_future)\n",
    "            final_forecasts[feature] = df.loc[df['ds'] <= \"2024-09\",feature].tolist() + list(np.round(alternative_forecast_poisson).astype(int))\n",
    "            df_val_t.loc[df_val_t['feature']==feature,'MAPE'] = best_mape\n",
    "            \n",
    "        elif best_mape == alternative_mape_ets:\n",
    "            print(f\"Using ETS model forecast for {feature}\")\n",
    "            alternative_forecast_ets = ets_model.forecast(120)\n",
    "            final_forecasts[feature] = df.loc[df['ds'] <= \"2024-09\",feature].tolist() + list(np.round(alternative_forecast_ets).astype(int))\n",
    "            df_val_t.loc[df_val_t['feature']==feature,'MAPE'] = best_mape\n",
    "        \n",
    "        else:\n",
    "            print(f\"Using SARIMAX forecast for {feature}\")\n",
    "            final_forecasts[feature] = sarimax_forecasts[feature]\n",
    "\n",
    "    \n",
    "    good_features = [i for i in df.columns if i not in poor_forecast + ['ds']]\n",
    "    final_forecasts = pd.merge(final_forecasts, sarimax_forecasts[['ds'] + good_features], on='ds', how='left')\n",
    "    assert len(final_forecasts) == 333, len(final_forecasts)\n",
    "    return final_forecasts, df_val_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0711de8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "engine_1_fc: \n",
      "['hour_of_day_6', 'hour_of_day_3']\n",
      "Processing feature: hour_of_day_6\n",
      "SARIMAX MAPE for hour_of_day_6: inf\n",
      "Alternative Model MAPE for hour_of_day_6: 3192142741470494.5\n",
      "Alternative Model MAPE for hour_of_day_6: 2051010677818874.8\n",
      "Using ETS model forecast for hour_of_day_6\n",
      "Processing feature: hour_of_day_3\n",
      "SARIMAX MAPE for hour_of_day_3: 48.3153175013337\n",
      "Alternative Model MAPE for hour_of_day_3: 0.8741685546592988\n",
      "Alternative Model MAPE for hour_of_day_3: 0.4250239441217267\n",
      "Using ETS model forecast for hour_of_day_3\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "engine_2_fc: \n",
      "['hour_of_day_8']\n",
      "Processing feature: hour_of_day_8\n",
      "SARIMAX MAPE for hour_of_day_8: 44.7383389694951\n",
      "Alternative Model MAPE for hour_of_day_8: 0.9629157617923325\n",
      "Alternative Model MAPE for hour_of_day_8: 0.23949193324497203\n",
      "Using ETS model forecast for hour_of_day_8\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "engine_3_fc: \n",
      "['civilian_injuries', 'inctype_grouped_descr_Smoke & CO Detector Install/Replacement', 'hour_of_day_9']\n",
      "Processing feature: civilian_injuries\n",
      "SARIMAX MAPE for civilian_injuries: inf\n",
      "Alternative Model MAPE for civilian_injuries: 30.0897173218388\n",
      "Alternative Model MAPE for civilian_injuries: 10662894917994.037\n",
      "Using Poisson model forecast for civilian_injuries\n",
      "Processing feature: inctype_grouped_descr_Smoke & CO Detector Install/Replacement\n",
      "SARIMAX MAPE for inctype_grouped_descr_Smoke & CO Detector Install/Replacement: inf\n",
      "Alternative Model MAPE for inctype_grouped_descr_Smoke & CO Detector Install/Replacement: 1.7306551793743478e+16\n",
      "Alternative Model MAPE for inctype_grouped_descr_Smoke & CO Detector Install/Replacement: 2799883846618235.0\n",
      "Using ETS model forecast for inctype_grouped_descr_Smoke & CO Detector Install/Replacement\n",
      "Processing feature: hour_of_day_9\n",
      "SARIMAX MAPE for hour_of_day_9: 48.95787004378592\n",
      "Alternative Model MAPE for hour_of_day_9: 1.7074938155265689\n",
      "Alternative Model MAPE for hour_of_day_9: 0.5961612697075447\n",
      "Using ETS model forecast for hour_of_day_9\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "engine_5_fc: \n",
      "['inctype_grouped_descr_Hazardous Condition']\n",
      "Processing feature: inctype_grouped_descr_Hazardous Condition\n",
      "SARIMAX MAPE for inctype_grouped_descr_Hazardous Condition: 60.41849123064168\n",
      "Alternative Model MAPE for inctype_grouped_descr_Hazardous Condition: 5.035048746613496\n",
      "Alternative Model MAPE for inctype_grouped_descr_Hazardous Condition: 0.7685188103128022\n",
      "Using ETS model forecast for inctype_grouped_descr_Hazardous Condition\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "engine_7_fc: \n",
      "['inctype_grouped_descr_Smoke & CO Detector Install/Replacement']\n",
      "Processing feature: inctype_grouped_descr_Smoke & CO Detector Install/Replacement\n",
      "SARIMAX MAPE for inctype_grouped_descr_Smoke & CO Detector Install/Replacement: inf\n",
      "Alternative Model MAPE for inctype_grouped_descr_Smoke & CO Detector Install/Replacement: 8.530554565541026\n",
      "Alternative Model MAPE for inctype_grouped_descr_Smoke & CO Detector Install/Replacement: 0.5164229770412968\n",
      "Using ETS model forecast for inctype_grouped_descr_Smoke & CO Detector Install/Replacement\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "engine_8_fc: \n",
      "['hour_of_day_15', 'hour_of_day_7', 'hour_of_day_21', 'hour_of_day_20']\n",
      "Processing feature: hour_of_day_15\n",
      "SARIMAX MAPE for hour_of_day_15: inf\n",
      "Alternative Model MAPE for hour_of_day_15: 865742258167451.0\n",
      "Alternative Model MAPE for hour_of_day_15: 767977611893529.9\n",
      "Using ETS model forecast for hour_of_day_15\n",
      "Processing feature: hour_of_day_7\n",
      "SARIMAX MAPE for hour_of_day_7: inf\n",
      "Alternative Model MAPE for hour_of_day_7: 1079295925846189.0\n",
      "Alternative Model MAPE for hour_of_day_7: 1326952886222641.8\n",
      "Using Poisson model forecast for hour_of_day_7\n",
      "Processing feature: hour_of_day_21\n",
      "SARIMAX MAPE for hour_of_day_21: inf\n",
      "Alternative Model MAPE for hour_of_day_21: 789847960831043.0\n",
      "Alternative Model MAPE for hour_of_day_21: 1020104967681014.1\n",
      "Using Poisson model forecast for hour_of_day_21\n",
      "Processing feature: hour_of_day_20\n",
      "SARIMAX MAPE for hour_of_day_20: inf\n",
      "Alternative Model MAPE for hour_of_day_20: 792616983848892.8\n",
      "Alternative Model MAPE for hour_of_day_20: 729075439642813.0\n",
      "Using ETS model forecast for hour_of_day_20\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "engine_9_fc: \n",
      "[]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "engine_10_truck_2_fc: \n",
      "[]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "engine_12_fc: \n",
      "['hour_of_day_10', 'hour_of_day_12']\n",
      "Processing feature: hour_of_day_10\n",
      "SARIMAX MAPE for hour_of_day_10: 54.683733226400776\n",
      "Alternative Model MAPE for hour_of_day_10: 0.5699185611000603\n",
      "Alternative Model MAPE for hour_of_day_10: 0.5320810959991162\n",
      "Using ETS model forecast for hour_of_day_10\n",
      "Processing feature: hour_of_day_12\n",
      "SARIMAX MAPE for hour_of_day_12: inf\n",
      "Alternative Model MAPE for hour_of_day_12: 0.6106981588449915\n",
      "Alternative Model MAPE for hour_of_day_12: 0.45300454765622256\n",
      "Using ETS model forecast for hour_of_day_12\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "engine_13_truck_10_fc: \n",
      "['day_name_Monday', 'hour_of_day_6', 'day_name_Tuesday', 'hour_of_day_23', 'hour_of_day_11', 'hour_of_day_4', 'alarmnum_1.0']\n",
      "Processing feature: day_name_Monday\n",
      "SARIMAX MAPE for day_name_Monday: 54.68986614892635\n",
      "Alternative Model MAPE for day_name_Monday: 15670578537.9031\n",
      "Alternative Model MAPE for day_name_Monday: 0.29052160892225676\n",
      "Using ETS model forecast for day_name_Monday\n",
      "Processing feature: hour_of_day_6\n",
      "SARIMAX MAPE for hour_of_day_6: inf\n",
      "Alternative Model MAPE for hour_of_day_6: 0.8581696023663116\n",
      "Alternative Model MAPE for hour_of_day_6: 0.2860684358878219\n",
      "Using ETS model forecast for hour_of_day_6\n",
      "Processing feature: day_name_Tuesday\n",
      "SARIMAX MAPE for day_name_Tuesday: 52.697132794701375\n",
      "Alternative Model MAPE for day_name_Tuesday: 17258175569.695698\n",
      "Alternative Model MAPE for day_name_Tuesday: 0.1881601219205821\n",
      "Using ETS model forecast for day_name_Tuesday\n",
      "Processing feature: hour_of_day_23\n",
      "SARIMAX MAPE for hour_of_day_23: 40.42930495563639\n",
      "Alternative Model MAPE for hour_of_day_23: 2.3010558708776276\n",
      "Alternative Model MAPE for hour_of_day_23: 0.2734529838143033\n",
      "Using ETS model forecast for hour_of_day_23\n",
      "Processing feature: hour_of_day_11\n",
      "SARIMAX MAPE for hour_of_day_11: 57.60172831741173\n",
      "Alternative Model MAPE for hour_of_day_11: 3.063584825519385\n",
      "Alternative Model MAPE for hour_of_day_11: 0.2501009264186158\n",
      "Using ETS model forecast for hour_of_day_11\n",
      "Processing feature: hour_of_day_4\n",
      "SARIMAX MAPE for hour_of_day_4: 71.45832255606241\n",
      "Alternative Model MAPE for hour_of_day_4: 1.2234550772483186\n",
      "Alternative Model MAPE for hour_of_day_4: 0.537421755962082\n",
      "Using ETS model forecast for hour_of_day_4\n",
      "Processing feature: alarmnum_1.0\n",
      "SARIMAX MAPE for alarmnum_1.0: 46.62927562309155\n",
      "Alternative Model MAPE for alarmnum_1.0: 7.060189518685252e+182\n",
      "Alternative Model MAPE for alarmnum_1.0: 0.09130877571338011\n",
      "Using ETS model forecast for alarmnum_1.0\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "engine_16_truck_6_fc: \n",
      "['hour_of_day_4']\n",
      "Processing feature: hour_of_day_4\n",
      "SARIMAX MAPE for hour_of_day_4: 50.7795095548457\n",
      "Alternative Model MAPE for hour_of_day_4: 0.7396322550085254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/medhinisridharr/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/medhinisridharr/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/medhinisridharr/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative Model MAPE for hour_of_day_4: 0.45994458442734626\n",
      "Using ETS model forecast for hour_of_day_4\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "engine_17_rescue_11_fc: \n",
      "['hour_of_day_6', 'hour_of_day_10', 'hour_of_day_12', 'hour_of_day_2']\n",
      "Processing feature: hour_of_day_6\n",
      "SARIMAX MAPE for hour_of_day_6: 53.21344465603146\n",
      "Alternative Model MAPE for hour_of_day_6: 1.827757029581272\n",
      "Alternative Model MAPE for hour_of_day_6: 0.31846446072251167\n",
      "Using ETS model forecast for hour_of_day_6\n",
      "Processing feature: hour_of_day_10\n",
      "SARIMAX MAPE for hour_of_day_10: 78.50984050186239\n",
      "Alternative Model MAPE for hour_of_day_10: 3.2476422056178054\n",
      "Alternative Model MAPE for hour_of_day_10: 0.2646301318728474\n",
      "Using ETS model forecast for hour_of_day_10\n",
      "Processing feature: hour_of_day_12\n",
      "SARIMAX MAPE for hour_of_day_12: 48.55163566674763\n",
      "Alternative Model MAPE for hour_of_day_12: 3.129892893974284\n",
      "Alternative Model MAPE for hour_of_day_12: 0.2653315195521573\n",
      "Using ETS model forecast for hour_of_day_12\n",
      "Processing feature: hour_of_day_2\n",
      "SARIMAX MAPE for hour_of_day_2: 75.85216369749263\n",
      "Alternative Model MAPE for hour_of_day_2: 1.7687441856913733\n",
      "Alternative Model MAPE for hour_of_day_2: 0.305366026551662\n",
      "Using ETS model forecast for hour_of_day_2\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "engine_19_fc: \n",
      "['hour_of_day_0', 'hour_of_day_13', 'day_name_Monday', 'inctype_grouped_descr_Smoke & CO Detector Install/Replacement', 'hour_of_day_15', 'sitfound_311.0']\n",
      "Processing feature: hour_of_day_0\n",
      "SARIMAX MAPE for hour_of_day_0: inf\n",
      "Alternative Model MAPE for hour_of_day_0: 2365966620864908.0\n",
      "Alternative Model MAPE for hour_of_day_0: 1729114613498237.8\n",
      "Using ETS model forecast for hour_of_day_0\n",
      "Processing feature: hour_of_day_13\n",
      "SARIMAX MAPE for hour_of_day_13: inf\n",
      "Alternative Model MAPE for hour_of_day_13: 0.44354848372841194\n",
      "Alternative Model MAPE for hour_of_day_13: 0.32696929625859816\n",
      "Using ETS model forecast for hour_of_day_13\n",
      "Processing feature: day_name_Monday\n",
      "SARIMAX MAPE for day_name_Monday: 42.78480255941142\n",
      "Alternative Model MAPE for day_name_Monday: 1.0074408889499944\n",
      "Alternative Model MAPE for day_name_Monday: 0.4137802940177719\n",
      "Using ETS model forecast for day_name_Monday\n",
      "Processing feature: inctype_grouped_descr_Smoke & CO Detector Install/Replacement\n",
      "SARIMAX MAPE for inctype_grouped_descr_Smoke & CO Detector Install/Replacement: inf\n",
      "Alternative Model MAPE for inctype_grouped_descr_Smoke & CO Detector Install/Replacement: 6161018694660616.0\n",
      "Alternative Model MAPE for inctype_grouped_descr_Smoke & CO Detector Install/Replacement: 945245066858550.6\n",
      "Using ETS model forecast for inctype_grouped_descr_Smoke & CO Detector Install/Replacement\n",
      "Processing feature: hour_of_day_15\n",
      "SARIMAX MAPE for hour_of_day_15: inf\n",
      "Alternative Model MAPE for hour_of_day_15: 0.646064734370064\n",
      "Alternative Model MAPE for hour_of_day_15: 0.4732022281633377\n",
      "Using ETS model forecast for hour_of_day_15\n",
      "Processing feature: sitfound_311.0\n",
      "SARIMAX MAPE for sitfound_311.0: inf\n",
      "Alternative Model MAPE for sitfound_311.0: 1942404376032696.0\n",
      "Alternative Model MAPE for sitfound_311.0: 1049595760275988.6\n",
      "Using ETS model forecast for sitfound_311.0\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "truck_3_fc: \n",
      "['hour_of_day_19', 'sitfound_321.0', 'inctype_grouped_descr_Hazardous Condition', 'inctype_grouped_descr_Service Calls']\n",
      "Processing feature: hour_of_day_19\n",
      "SARIMAX MAPE for hour_of_day_19: inf\n",
      "Alternative Model MAPE for hour_of_day_19: 1.4123521345821997\n",
      "Alternative Model MAPE for hour_of_day_19: 0.6114125837357813\n",
      "Using ETS model forecast for hour_of_day_19\n",
      "Processing feature: sitfound_321.0\n",
      "SARIMAX MAPE for sitfound_321.0: 54.550935266415046\n",
      "Alternative Model MAPE for sitfound_321.0: 0.7718388626020747\n",
      "Alternative Model MAPE for sitfound_321.0: 0.13182546428678416\n",
      "Using ETS model forecast for sitfound_321.0\n",
      "Processing feature: inctype_grouped_descr_Hazardous Condition\n",
      "SARIMAX MAPE for inctype_grouped_descr_Hazardous Condition: inf\n",
      "Alternative Model MAPE for inctype_grouped_descr_Hazardous Condition: 1.8160051946188913\n",
      "Alternative Model MAPE for inctype_grouped_descr_Hazardous Condition: 0.48917814390857184\n",
      "Using ETS model forecast for inctype_grouped_descr_Hazardous Condition\n",
      "Processing feature: inctype_grouped_descr_Service Calls\n",
      "SARIMAX MAPE for inctype_grouped_descr_Service Calls: 71.98829416898663\n",
      "Alternative Model MAPE for inctype_grouped_descr_Service Calls: 1.7869978911224245\n",
      "Alternative Model MAPE for inctype_grouped_descr_Service Calls: 0.9475703701345657\n",
      "Using ETS model forecast for inctype_grouped_descr_Service Calls\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "truck_4_fc: \n",
      "['day_name_Wednesday', 'inctype_grouped_descr_Severe Weather', 'hour_of_day_23', 'hour_of_day_3', 'hour_of_day_1']\n",
      "Processing feature: day_name_Wednesday\n",
      "SARIMAX MAPE for day_name_Wednesday: 51.625393290818735\n",
      "Alternative Model MAPE for day_name_Wednesday: 2.9413194255471447\n",
      "Alternative Model MAPE for day_name_Wednesday: 0.4856265070470812\n",
      "Using ETS model forecast for day_name_Wednesday\n",
      "Processing feature: inctype_grouped_descr_Severe Weather\n",
      "SARIMAX MAPE for inctype_grouped_descr_Severe Weather: inf\n",
      "Alternative Model MAPE for inctype_grouped_descr_Severe Weather: 121480587860990.69\n",
      "Alternative Model MAPE for inctype_grouped_descr_Severe Weather: 656766358633948.1\n",
      "Using Poisson model forecast for inctype_grouped_descr_Severe Weather\n",
      "Processing feature: hour_of_day_23\n",
      "SARIMAX MAPE for hour_of_day_23: inf\n",
      "Alternative Model MAPE for hour_of_day_23: 3741410392774071.0\n",
      "Alternative Model MAPE for hour_of_day_23: 1863170986282351.2\n",
      "Using ETS model forecast for hour_of_day_23\n",
      "Processing feature: hour_of_day_3\n",
      "SARIMAX MAPE for hour_of_day_3: inf\n",
      "Alternative Model MAPE for hour_of_day_3: 1921784723383118.5\n",
      "Alternative Model MAPE for hour_of_day_3: 1480717849969166.8\n",
      "Using ETS model forecast for hour_of_day_3\n",
      "Processing feature: hour_of_day_1\n",
      "SARIMAX MAPE for hour_of_day_1: inf\n",
      "Alternative Model MAPE for hour_of_day_1: 2279611016189610.5\n",
      "Alternative Model MAPE for hour_of_day_1: 1246532088081151.5\n",
      "Using ETS model forecast for hour_of_day_1\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "truck_5_fc: \n",
      "['hour_of_day_7', 'inctype_grouped_descr_Service Calls']\n",
      "Processing feature: hour_of_day_7\n",
      "SARIMAX MAPE for hour_of_day_7: 44.99908953822924\n",
      "Alternative Model MAPE for hour_of_day_7: 1.727493902908633\n",
      "Alternative Model MAPE for hour_of_day_7: 0.49270423734324414\n",
      "Using ETS model forecast for hour_of_day_7\n",
      "Processing feature: inctype_grouped_descr_Service Calls\n",
      "SARIMAX MAPE for inctype_grouped_descr_Service Calls: 60.402623278636455\n",
      "Alternative Model MAPE for inctype_grouped_descr_Service Calls: 3.9705070137918494\n",
      "Alternative Model MAPE for inctype_grouped_descr_Service Calls: 0.5211219878903245\n",
      "Using ETS model forecast for inctype_grouped_descr_Service Calls\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_forecasts_data_dict = {}\n",
    "for (f,v) in zip(forecasts_data_dict.keys(),val_data_dict.keys()):\n",
    "    print(f+': ')\n",
    "    \n",
    "    test_val_t = val_data_transpose_dict[v]\n",
    "    p=[i for i in test_val_t.loc[test_val_t['MAPE']>40,'feature'].tolist() if i!='is_covid']\n",
    "    \n",
    "    globals()['final_'+f], globals()[v+'_t']  = improve_forecast(forecasts_data_dict[f], val_data_dict[v], val_data_transpose_dict[v],p)\n",
    "    final_forecasts_data_dict[f] = globals()['final_'+f]\n",
    "    val_data_transpose_dict[v] = globals()[v+'_t']\n",
    "    print('-'*80)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc2f56ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "engine_1_val\n",
      "engine_2_val\n",
      "engine_3_val\n",
      "engine_5_val\n",
      "engine_7_val\n",
      "engine_8_val\n",
      "engine_9_val\n",
      "engine_10_truck_2_val\n",
      "engine_12_val\n",
      "engine_13_truck_10_val\n",
      "engine_16_truck_6_val\n",
      "engine_17_rescue_11_val\n",
      "engine_19_val\n",
      "truck_3_val\n",
      "truck_4_val\n",
      "truck_5_val\n"
     ]
    }
   ],
   "source": [
    "for k in val_data_dict.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f532fa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (k,v) in val_data_transpose_dict.items():\n",
    "    v.to_csv(f'/Users/medhinisridharr/Documents/University of Rochester/Courses/Fall 2024/Capstone Project/monthly_incident_counts/Forecasted Selected Features/corrected_validation_metrics/{k}_cor_val.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd5c8c5",
   "metadata": {},
   "source": [
    "## Predicting Monthly Incident Counts using Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89168243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>engine_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>engine_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>engine_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>engine_5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>engine_7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>engine_8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>engine_9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>engine_10_truck_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>engine_12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>engine_13_truck_10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>engine_16_truck_6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>engine_17_rescue_11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>engine_19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>truck_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>truck_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>truck_5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           station_name  MAE RMSE MAPE\n",
       "0              engine_1  NaN  NaN  NaN\n",
       "1              engine_2  NaN  NaN  NaN\n",
       "2              engine_3  NaN  NaN  NaN\n",
       "3              engine_5  NaN  NaN  NaN\n",
       "4              engine_7  NaN  NaN  NaN\n",
       "5              engine_8  NaN  NaN  NaN\n",
       "6              engine_9  NaN  NaN  NaN\n",
       "7     engine_10_truck_2  NaN  NaN  NaN\n",
       "8             engine_12  NaN  NaN  NaN\n",
       "9    engine_13_truck_10  NaN  NaN  NaN\n",
       "10    engine_16_truck_6  NaN  NaN  NaN\n",
       "11  engine_17_rescue_11  NaN  NaN  NaN\n",
       "12            engine_19  NaN  NaN  NaN\n",
       "13              truck_3  NaN  NaN  NaN\n",
       "14              truck_4  NaN  NaN  NaN\n",
       "15              truck_5  NaN  NaN  NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create eval metrics table\n",
    "prophet_metrics_df = pd.DataFrame(columns=['station_name','MAE','RMSE','MAPE'])\n",
    "prophet_metrics_df['station_name'] = csv_names\n",
    "prophet_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713e8e69",
   "metadata": {},
   "source": [
    "### Prophet Model:\n",
    "- Training: Train on data till year = 2023 (inclusive)\n",
    "    - Add regressors and then train\n",
    "- Test: Test on January 2024 - September 2024\n",
    "- Calculate evaluation metrics\n",
    "- Train on entire data\n",
    "    - Add regressors and then train\n",
    "- Predict for future periods: October 2024 - September 2034\n",
    "- Using final forecasted values for monthly incident counts, plot data from 2007 to 2034."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "577bca04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:10:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:45 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:49 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:49 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:10:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:11:00 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "for (n,v) in zip(csv_names,final_forecasts_data_dict.values()):\n",
    "    v['ds'] = pd.to_datetime(v['ds'])\n",
    "    train = v[v['ds'].dt.year <= 2023].reset_index(drop=True)\n",
    "    test = v[(v['ds'].dt.year > 2023) & (v['ds']<= \"2024-09\")].reset_index(drop=True)\n",
    "\n",
    "    # Prepare data for Prophet (rename columns as Prophet expects specific column names)\n",
    "    train_data = train.rename(columns={'monthly_incidents_per_nearest_station_count': 'y'})\n",
    "    test_data = test.rename(columns={'monthly_incidents_per_nearest_station_count': 'y'})\n",
    "\n",
    "    #Add indepenent features (historical + forecasted values) as regressors in the Prophet model\n",
    "    regressors_list = [i for i in train_data.columns if i not in ['ds','y']]\n",
    "\n",
    "    missing_columns = [col for col in regressors_list if col not in test_data.columns]\n",
    "    assert len(missing_columns)==0, f\"Missing columns are {missing_columns}\"\n",
    "\n",
    "    # Initialize and train the Prophet model\n",
    "    model = Prophet()\n",
    "\n",
    "    for regressor in regressors_list:\n",
    "        model.add_regressor(regressor)\n",
    "\n",
    "    model.fit(train_data)\n",
    "\n",
    "    # Make future dataframe for test period\n",
    "    future = test_data[['ds']].copy()\n",
    "    for regressor in regressors_list:\n",
    "        future[regressor] = test_data[regressor]\n",
    "\n",
    "    # Predict using the trained model\n",
    "    forecast = model.predict(future)\n",
    "\n",
    "    # Evaluate the model\n",
    "    actuals = test_data['y'].values\n",
    "    predictions = forecast['yhat'].values\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    mae = mean_absolute_error(actuals, predictions)\n",
    "    rmse = mean_squared_error(actuals, predictions, squared=False)\n",
    "    mape = (np.abs(actuals - predictions) / actuals).mean() * 100\n",
    "\n",
    "    #Add metrics in the table\n",
    "    prophet_metrics_df.loc[prophet_metrics_df['station_name']==n,'MAE'] = mae\n",
    "    prophet_metrics_df.loc[prophet_metrics_df['station_name']==n,'RMSE'] = rmse\n",
    "    prophet_metrics_df.loc[prophet_metrics_df['station_name']==n,'MAPE'] = mape\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test_data['ds'], actuals, label='Actuals', marker='o')\n",
    "    plt.plot(test_data['ds'], predictions, label='Forecast', marker='x')\n",
    "    plt.title(f\"Prophet Model for {n}: Forecast vs Actuals\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Monthly Incident Counts\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f'/Users/medhinisridharr/Documents/University of Rochester/Courses/Fall 2024/Capstone Project/monthly_incident_counts/Predicted Monthly Incident Counts/Plots - Forecast vs Actuals/{n}_forecast_vs_actuals.png', format='png', dpi=300)  # Save the plot as a PNG file with high resolution\n",
    "    plt.close()\n",
    "\n",
    "    # Combine train and test data into a single dataset\n",
    "    full_data = pd.concat([train_data, test_data], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    forecasted_values = v[v['ds']>= \"2024-10\"].reset_index(drop=True)\n",
    "\n",
    "    for feature in forecasted_values.columns:\n",
    "        if feature not in ['ds','monthly_incidents_per_nearest_station_count']:\n",
    "            #Preprocessing - if SARIMAX has predicted negative counts and this is more than 50% - drop, otherwise, force to 0\n",
    "            if len(forecasted_values[forecasted_values[feature] < 0]) / len(forecasted_values) > 0.5:\n",
    "                forecasted_values = forecasted_values.drop(feature, axis=1)\n",
    "                regressors_list.remove(feature)\n",
    "                full_data = full_data.drop(feature, axis=1)\n",
    "            else:\n",
    "                forecasted_values[feature] = np.where(forecasted_values[feature] < 0, 0, forecasted_values[feature])\n",
    "            \n",
    "                # Round forecasted values to the nearest integer since they are counts\n",
    "                forecasted_values[feature] = forecasted_values[feature].round().astype(int)\n",
    "\n",
    "    # Initialize the Prophet model\n",
    "    final_model = Prophet(changepoint_prior_scale=0.5, uncertainty_samples=3000)\n",
    "\n",
    "    # Add regressors to the model\n",
    "    for regressor in regressors_list:\n",
    "        final_model.add_regressor(regressor)\n",
    "\n",
    "    # Fit the model on the full historical data\n",
    "    final_model.fit(full_data)\n",
    "\n",
    "    # Create a DataFrame for future predictions (next 10 years)\n",
    "    # Ensure the future DataFrame has columns for all regressors\n",
    "    future_periods = pd.date_range(start=\"2024-10-01\", end=\"2034-09-01\", freq='MS')  # Monthly start\n",
    "    future = pd.DataFrame({'ds': future_periods})\n",
    "\n",
    "    # Add forecasted regressor values for the future period\n",
    "    for regressor in regressors_list:\n",
    "        # Replace with your forecasted regressor data\n",
    "        future[regressor] = forecasted_values[regressor]  # Ensure `forecasted_values` is defined\n",
    "\n",
    "    # Predict using the trained model\n",
    "    final_forecast = final_model.predict(future)\n",
    "\n",
    "    # Amplify uncertainty intervals for better visualization\n",
    "#     amplification_factor = 2  # Adjust this factor as needed\n",
    "#     final_forecast['yhat_lower_vis'] = final_forecast['yhat'] - amplification_factor * (final_forecast['yhat'] - final_forecast['yhat_lower'])\n",
    "#     final_forecast['yhat_upper_vis'] = final_forecast['yhat'] + amplification_factor * (final_forecast['yhat_upper'] - final_forecast['yhat'])\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(full_data['ds'], full_data['y'], label='Historical Data', marker='o', linestyle='-')\n",
    "    plt.plot(final_forecast['ds'], final_forecast['yhat'], label='Forecast (2024-2034)', marker='x', linestyle='--')\n",
    "\n",
    "    # Plot the uncertainty interval\n",
    "    plt.fill_between(final_forecast['ds'], \n",
    "                     final_forecast['yhat_lower'], \n",
    "                     final_forecast['yhat_upper'], \n",
    "                     color='blue', \n",
    "                     alpha=0.2, \n",
    "                     label='Uncertainty Interval')\n",
    "    plt.title(f\"{n}: Monthly Incident Counts Forecast (2024-2034)\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Monthly Incident Counts\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f'/Users/medhinisridharr/Documents/University of Rochester/Courses/Fall 2024/Capstone Project/monthly_incident_counts/Predicted Monthly Incident Counts/Plots - Future Counts/{n}_monthly_counts_forecast.png', format='png', dpi=300)  # Save the plot as a PNG file with high resolution\n",
    "    plt.close()\n",
    "    \n",
    "    # Combine historical and forecasted data\n",
    "    historical_data = full_data.copy()  # Historical data (2007-2024)\n",
    "    historical_data = historical_data[['ds', 'y'] + regressors_list]  # Include 'ds', 'y', and regressors\n",
    "    historical_data = historical_data.rename(columns={'y': 'monthly_incidents_per_nearest_station_count'})\n",
    "\n",
    "    forecast_data = final_forecast[['ds', 'yhat'] + [f'{regressor}' for regressor in regressors_list]].copy()\n",
    "    forecast_data = forecast_data.rename(columns={'yhat': 'monthly_incidents_per_nearest_station_count'})\n",
    "\n",
    "    # Combine historical and forecasted data\n",
    "    combined_data = pd.concat([historical_data, forecast_data], axis=0).reset_index(drop=True)\n",
    "\n",
    "    # Ensure the date range is from Jan 2007 to Sep 2034\n",
    "    date_range = pd.date_range(start=\"2007-01-01\", end=\"2034-09-01\", freq='MS')\n",
    "    final_combined_data = pd.DataFrame({'ds': date_range}).merge(combined_data, on='ds', how='left')\n",
    "\n",
    "    # Save to CSV\n",
    "    final_combined_data.to_csv(f'/Users/medhinisridharr/Documents/University of Rochester/Courses/Fall 2024/Capstone Project/monthly_incident_counts/Predicted Monthly Incident Counts/Forecasted Data/{n}_historical_forecasted_values.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "062ee113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>engine_1</td>\n",
       "      <td>0.291661</td>\n",
       "      <td>0.460196</td>\n",
       "      <td>0.142126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>engine_2</td>\n",
       "      <td>0.781801</td>\n",
       "      <td>0.820729</td>\n",
       "      <td>0.20228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>engine_3</td>\n",
       "      <td>0.140351</td>\n",
       "      <td>0.190015</td>\n",
       "      <td>0.077823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>engine_5</td>\n",
       "      <td>0.474015</td>\n",
       "      <td>0.489339</td>\n",
       "      <td>0.260761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>engine_7</td>\n",
       "      <td>0.184456</td>\n",
       "      <td>0.209461</td>\n",
       "      <td>0.091862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>engine_8</td>\n",
       "      <td>0.014136</td>\n",
       "      <td>0.01694</td>\n",
       "      <td>0.036455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>engine_9</td>\n",
       "      <td>0.295105</td>\n",
       "      <td>0.402123</td>\n",
       "      <td>0.108305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>engine_10_truck_2</td>\n",
       "      <td>0.642628</td>\n",
       "      <td>0.670564</td>\n",
       "      <td>0.222747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>engine_12</td>\n",
       "      <td>0.34545</td>\n",
       "      <td>0.7522</td>\n",
       "      <td>0.534572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>engine_13_truck_10</td>\n",
       "      <td>0.391101</td>\n",
       "      <td>0.471319</td>\n",
       "      <td>0.159016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>engine_16_truck_6</td>\n",
       "      <td>0.373438</td>\n",
       "      <td>0.47122</td>\n",
       "      <td>0.165791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>engine_17_rescue_11</td>\n",
       "      <td>0.487572</td>\n",
       "      <td>0.570244</td>\n",
       "      <td>0.175463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>engine_19</td>\n",
       "      <td>0.036637</td>\n",
       "      <td>0.049952</td>\n",
       "      <td>0.052715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>truck_3</td>\n",
       "      <td>0.13337</td>\n",
       "      <td>0.149695</td>\n",
       "      <td>0.14539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>truck_4</td>\n",
       "      <td>0.407708</td>\n",
       "      <td>0.527684</td>\n",
       "      <td>0.472241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>truck_5</td>\n",
       "      <td>0.436042</td>\n",
       "      <td>0.620976</td>\n",
       "      <td>0.218109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           station_name       MAE      RMSE      MAPE\n",
       "0              engine_1  0.291661  0.460196  0.142126\n",
       "1              engine_2  0.781801  0.820729   0.20228\n",
       "2              engine_3  0.140351  0.190015  0.077823\n",
       "3              engine_5  0.474015  0.489339  0.260761\n",
       "4              engine_7  0.184456  0.209461  0.091862\n",
       "5              engine_8  0.014136   0.01694  0.036455\n",
       "6              engine_9  0.295105  0.402123  0.108305\n",
       "7     engine_10_truck_2  0.642628  0.670564  0.222747\n",
       "8             engine_12   0.34545    0.7522  0.534572\n",
       "9    engine_13_truck_10  0.391101  0.471319  0.159016\n",
       "10    engine_16_truck_6  0.373438   0.47122  0.165791\n",
       "11  engine_17_rescue_11  0.487572  0.570244  0.175463\n",
       "12            engine_19  0.036637  0.049952  0.052715\n",
       "13              truck_3   0.13337  0.149695   0.14539\n",
       "14              truck_4  0.407708  0.527684  0.472241\n",
       "15              truck_5  0.436042  0.620976  0.218109"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07037ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. MAE across stations: 0.34\n",
      "Avg. RMSE across stations: 0.43\n",
      "Avg. MAPE across stations: 0.192\n"
     ]
    }
   ],
   "source": [
    "print('Avg. MAE across stations: '+str(round(prophet_metrics_df['MAE'].mean(),3)))\n",
    "print('Avg. RMSE across stations: '+str(round(prophet_metrics_df['RMSE'].mean(),3)))\n",
    "print('Avg. MAPE across stations: '+str(round(prophet_metrics_df['MAPE'].mean(),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97f643fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median MAE across stations: 0.359\n",
      "Median RMSE across stations: 0.471\n",
      "Median MAPE across stations: 0.162\n"
     ]
    }
   ],
   "source": [
    "print('Median MAE across stations: '+str(round(prophet_metrics_df['MAE'].median(),3)))\n",
    "print('Median RMSE across stations: '+str(round(prophet_metrics_df['RMSE'].median(),3)))\n",
    "print('Median MAPE across stations: '+str(round(prophet_metrics_df['MAPE'].median(),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d9314fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_metrics_df.to_csv('prophet_metrics.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8553ecce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>engine_1</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>engine_2</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>engine_3</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>engine_5</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>engine_7</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>engine_8</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>engine_9</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>engine_10_truck_2</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>engine_12</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>engine_13_truck_10</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>engine_16_truck_6</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>engine_17_rescue_11</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>engine_19</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>truck_3</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>truck_4</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>truck_5</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           station_name    MAE   RMSE   MAPE\n",
       "0              engine_1  0.292  0.460  0.142\n",
       "1              engine_2  0.782  0.821  0.202\n",
       "2              engine_3  0.140  0.190  0.078\n",
       "3              engine_5  0.474  0.489  0.261\n",
       "4              engine_7  0.184  0.209  0.092\n",
       "5              engine_8  0.014  0.017  0.036\n",
       "6              engine_9  0.295  0.402  0.108\n",
       "7     engine_10_truck_2  0.643  0.671  0.223\n",
       "8             engine_12  0.345  0.752  0.535\n",
       "9    engine_13_truck_10  0.391  0.471  0.159\n",
       "10    engine_16_truck_6  0.373  0.471  0.166\n",
       "11  engine_17_rescue_11  0.488  0.570  0.175\n",
       "12            engine_19  0.037  0.050  0.053\n",
       "13              truck_3  0.133  0.150  0.145\n",
       "14              truck_4  0.408  0.528  0.472\n",
       "15              truck_5  0.436  0.621  0.218"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet_metrics_df[['MAE', 'RMSE', 'MAPE']] = prophet_metrics_df[['MAE', 'RMSE', 'MAPE']].astype(float).round(3)\n",
    "prophet_metrics_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
